import requests
from bs4 import BeautifulSoup
import csv

def scrape_website(url):
    # Send a GET request to the URL
    response = requests.get(url)
    
    # Check if request was successful
    if response.status_code == 200:
        # Parse the HTML content
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Find relevant HTML elements containing the information you want to scrape
        titles = soup.find_all('h2', class_='article-title')  # Example: scraping article titles
        
        # Store the extracted data in a structured format (e.g., CSV)
        with open('data.csv', 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['Title'])
            
            for title in titles:
                writer.writerow([title.text.strip()])

        print("Data scraped and saved successfully.")
    else:
        print("Failed to retrieve website content.")

if __name__ == "__main__":
    url = 'https://example.com'  # Replace with the URL of the website you want to scrape
    scrape_website(url)
